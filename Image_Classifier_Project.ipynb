{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier Project Development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Check if GPU is available\u001b[39;00m\n\u001b[0;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define transforms for training, validation, and testing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load datasets with ImageFolder\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(valid_dir, transform=data_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size=batch_size),\n",
    "    'test': torch.utils.data.DataLoader(image_datasets['test'], batch_size=batch_size)\n",
    "}\n",
    "\n",
    "# Load category names\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "print(\"Number of training images:\", len(image_datasets['train']))\n",
    "print(\"Number of validation images:\", len(image_datasets['valid']))\n",
    "print(\"Number of test images:\", len(image_datasets['test']))\n",
    "print(\"Number of categories:\", len(cat_to_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category names\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "\n",
    "print(\"Number of training images:\", len(image_datasets['train']))\n",
    "print(\"Number of validation images:\", len(image_datasets['valid']))\n",
    "print(\"Number of test images:\", len(image_datasets['test']))\n",
    "print(\"Number of categories:\", len(cat_to_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model (VGG16)\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define classifier\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088, 4096)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('dropout1', nn.Dropout(0.5)),\n",
    "    ('fc2', nn.Linear(4096, 102)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model.classifier = classifier\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Add learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps = 0\n",
    "print_every = 40\n",
    "best_accuracy = 0\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop with progress bar\n",
    "    train_bar = tqdm(dataloaders['train'], desc=f'Epoch {epoch+1}/{epochs}')\n",
    "    for inputs, labels in train_bar:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.set_postfix({'train_loss': loss.item()})\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in dataloaders['valid']:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    valid_loss += criterion(outputs, labels).item()\n",
    "                    \n",
    "                    ps = torch.exp(outputs)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            train_loss = running_loss/print_every\n",
    "            valid_loss = valid_loss/len(dataloaders['valid'])\n",
    "            accuracy = accuracy/len(dataloaders['valid'])\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "            scheduler.step(valid_loss)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'accuracy': accuracy,\n",
    "                }, 'best_model.pth')\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \n",
    "                  Train loss: {train_loss:.3f}.. \n",
    "                  Validation loss: {valid_loss:.3f}.. \n",
    "                  Accuracy: {accuracy:.3f}\")\n",
    "            \n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(dataloaders['test'], desc='Testing')\n",
    "    for inputs, labels in test_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_loss += criterion(outputs, labels).item()\n",
    "        \n",
    "        ps = torch.exp(outputs)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        test_bar.set_postfix({'test_accuracy': test_accuracy/len(dataloaders['test'])})\n",
    "\n",
    "test_loss = test_loss/len(dataloaders['test'])\n",
    "test_accuracy = test_accuracy/len(dataloaders['test'])\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'arch': 'vgg16',\n",
    "    'classifier': model.classifier,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'class_to_idx': image_datasets['train'].class_to_idx,\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'epochs': epochs,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "print(\"Checkpoint saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    model = models.vgg16(pretrained=True)\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test loading checkpoint\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(\"Checkpoint loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    ''' Process image for model input '''\n",
    "    # Open image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Define transforms\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Process image\n",
    "    img_tensor = preprocess(img)\n",
    "    \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict class from an image '''\n",
    "    # Process image\n",
    "    img = process_image(image_path)\n",
    "    img = img.unsqueeze_(0).to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        ps = torch.exp(output)\n",
    "        top_p, top_class = ps.topk(topk, dim=1)\n",
    "    \n",
    "    # Convert indices to classes\n",
    "    idx_to_class = {v: k for k, v in model.class_to_idx.items()}\n",
    "    classes = [idx_to_class[i] for i in top_class.cpu().numpy()[0]]\n",
    "    probs = top_p.cpu().numpy()[0]\n",
    "    \n",
    "    return probs, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Sanity Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(image_path, model, topk=5):\n",
    "    ''' Display image and prediction '''\n",
    "    # Get prediction\n",
    "    probs, classes = predict(image_path, model, topk)\n",
    "    flower_names = [cat_to_name[c] for c in classes]\n",
    "    \n",
    "    # Plot image\n",
    "    img = Image.open(image_path)\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(12,4), nrows=1, ncols=2)\n",
    "    \n",
    "    # Plot flower\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(f'Actual: {cat_to_name[image_path.split(\"/\")[-2]]}')\n",
    "    \n",
    "    # Plot probabilities\n",
    "    ax2.barh(np.arange(topk), probs)\n",
    "    ax2.set_yticks(np.arange(topk))\n",
    "    ax2.set_yticklabels(flower_names)\n",
    "    ax2.set_xlabel('Probability')\n",
    "    ax2.set_title('Top 5 Predictions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test prediction\n",
    "test_image = 'flowers/test/1/image_06743.jpg'\n",
    "plot_prediction(test_image, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
